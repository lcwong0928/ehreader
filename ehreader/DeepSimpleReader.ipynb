{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7f6ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, BertConfig ,DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from transformers import DistilBertModel, DistilBertConfig\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22415e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ermQA(torch.utils.data.Dataset):\n",
    "    def __init__(self, filename):\n",
    "        with open(f\"processed_data/{filename}.pickle\", \"rb\") as f:\n",
    "            self.encodings = pickle.load(f)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd358b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBERTEncoder(torch.nn.Module):\n",
    "    def __init__(self, frozen=True):\n",
    "        super(DistilBERTEncoder, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained('dmis-lab/biobert-v1.1', output_hidden_states = True)\n",
    "        self.encoder.to(device)\n",
    "        if frozen:\n",
    "            self.encoder.requires_grad = False\n",
    "            self.encoder.eval()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.encoder(input_ids, attention_mask = attention_mask)\n",
    "        embedding = output.last_hidden_state # [batch, 512, 3072]\n",
    "\n",
    "        return embedding\n",
    "    \n",
    "    \n",
    "class SimpleReader(torch.nn.Module):\n",
    "    def __init__(self, in_features=768, out_features=1):\n",
    "        super(SimpleReader, self).__init__()\n",
    "        self.encoder = DistilBERTEncoder(frozen=False)\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.encoder(input_ids, attention_mask = attention_mask)\n",
    "        embedding_first_token = torch.squeeze(embeddings[:, 0, :], axis = 1) # [batch, 3072]    \n",
    "        linear = self.linear(embedding_first_token) # [batch, 1] \n",
    "        logit = self.sigmoid(linear)  # [batch, 1]   \n",
    "        return logit\n",
    "    \n",
    "class DeepReader(torch.nn.Module):\n",
    "    def __init__(self, embed_size=768, num_heads=1):\n",
    "        super(DeepReader, self).__init__()\n",
    "        self.encoder = DistilBERTEncoder(frozen=False)\n",
    "        \n",
    "        # Self attention on passage \n",
    "        self.passage_key_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.passage_value_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.passage_query_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.passage_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        # Self attention on question \n",
    "        self.question_key_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.question_value_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.question_query_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.question_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        # Cross attention \n",
    "        self.cross_query_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.cross_key_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.cross_value_linear = nn.Linear(embed_size, embed_size)\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        # Feed forward neural network (FFN)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(embed_size, embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_size, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.encoder(input_ids, attention_mask = attention_mask)\n",
    "        \n",
    "        token_split_index = self.generate_token_split_index(input_ids)\n",
    "\n",
    "        passage, question = torch.tensor_split(embeddings, token_split_index, dim=1)\n",
    "\n",
    "        passage_key = self.passage_key_linear(passage)\n",
    "        passage_value = self.passage_value_linear(passage)\n",
    "        passage_query = self.passage_query_linear(passage)\n",
    "        passage_after_attention, _ = self.passage_attention(query=passage_query, key=passage_key, value=passage_value)\n",
    "\n",
    "        question_key = self.question_key_linear(question)\n",
    "        question_value = self.question_value_linear(question)\n",
    "        question_query = self.question_query_linear(question)\n",
    "        question_after_attention, _ = self.question_attention(query=question_query, key=question_key, value=question_value)\n",
    "\n",
    "        cross_query = self.cross_query_linear(passage_after_attention)\n",
    "        cross_key = self.cross_key_linear(question_after_attention)\n",
    "        cross_value = self.cross_value_linear(question_after_attention)\n",
    "        cross_attention_embedding, _ = self.cross_attention(query=cross_query, key=cross_key, value=cross_value)\n",
    "\n",
    "        ffn_output = self.linear_relu_stack(cross_attention_embedding)\n",
    "        output = nn.functional.softmax(ffn_output, dim=1)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def generate_token_split_index(self, input_ids):\n",
    "        token_split_index = []\n",
    "        sep_tokens = (input_ids == 102).nonzero(as_tuple=True)\n",
    "        used_samples = set()\n",
    "        for i, index in zip(sep_tokens[0], sep_tokens[1]):\n",
    "            if i.item() not in used_samples:\n",
    "                token_split_index.append(index.item())\n",
    "                used_samples.add(i.item())\n",
    "        return token_split_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52cda00",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e470c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_match(prediction, truth):\n",
    "    exact_match = 0\n",
    "    for pred, tru in zip(prediction, truth):\n",
    "        if pred == tru:\n",
    "            exact_match += 1\n",
    "    return exact_match / len(prediction)\n",
    "\n",
    "\n",
    "def getOverlap(a, b):\n",
    "    return max(0, min(a[1], b[1]) - max(a[0], b[0]))\n",
    "\n",
    "\n",
    "def compute_tav_fast(start_logit, end_logit):\n",
    "    start_probs, end_probs = (torch.softmax(start_logit, dim=0), torch.softmax(end_logit, dim=0))\n",
    "    n = len(start_logit)\n",
    "    s_null = start_probs[0] + end_probs[0]\n",
    "    s_has = 0\n",
    "    best_span = (0, 0)\n",
    "    high_start_idx = 1\n",
    "  \n",
    "    for i in range(1, n):\n",
    "        if start_probs[i] > start_probs[high_start_idx]:\n",
    "            high_start_idx = i\n",
    "        if start_probs[high_start_idx] + end_probs[i] > s_has:\n",
    "            s_has = start_probs[high_start_idx] + end_probs[i]\n",
    "            best_span = (high_start_idx, i)\n",
    "            \n",
    "    s_diff = s_null - s_has\n",
    "    return s_diff.item(), best_span\n",
    "\n",
    "def compute_s_ext(sr_logit):\n",
    "    s_ext =  1 - 2*sr_logit.item()\n",
    "    return s_ext\n",
    "\n",
    "def compute_rv(sr_logit, start_logit, end_logit, weight=.5):\n",
    "    s_ext = compute_s_ext(sr_logit)\n",
    "    s_diff, best_span = compute_tav_fast(start_logit, end_logit)\n",
    "    rv = weight * s_diff + (1-weight) * s_ext\n",
    "    return rv, best_span\n",
    "\n",
    "def compute_f1(prediction, truth, input_id_list):\n",
    "    \n",
    "    f1_scores = []\n",
    "    \n",
    "    for i, (pred, gold) in enumerate(zip(prediction, truth)):\n",
    "        \n",
    "        if pred == gold:\n",
    "            f1_scores.append(1)\n",
    "            \n",
    "        else:\n",
    "            pred_tokens = input_id_list[i-1][pred[0]: pred[1]+1]\n",
    "            gold_tokens = input_id_list[i-1][gold[0]: gold[1]+1]\n",
    "\n",
    "            total_overlap = len(set(pred_tokens).intersection(set(gold_tokens)))\n",
    "            total_tru = len(gold_tokens)\n",
    "            total_pred = len(pred_tokens)\n",
    "\n",
    "            if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
    "                f1_scores.append(int(pred_tokens == gold_tokens))\n",
    "            elif total_overlap == 0:\n",
    "                f1_scores.append(0)\n",
    "            else:\n",
    "                prec = total_overlap / total_pred\n",
    "                rec = total_overlap / total_tru\n",
    "                f1_scores.append(2 * (prec * rec) / (prec + rec))\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2c0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(simple_model, deep_model, data_loader, dataset, split):\n",
    "    truths = []\n",
    "    \n",
    "    # Greedy\n",
    "    spans_greedy = []\n",
    "    \n",
    "    # RV\n",
    "    rvs = []\n",
    "    spans_rv = []\n",
    "    \n",
    "    input_id_list = []\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "\n",
    "        # we don't need to calculate gradients as we're not training\n",
    "        with torch.no_grad():\n",
    "            # Truth Span\n",
    "            for i, j, k in zip(batch['start_positions'], batch['end_positions'], batch['input_ids']):\n",
    "                truths.append((i.item(), j.item()))\n",
    "                input_id_list.append(k.tolist())\n",
    "        \n",
    "            # Predictions\n",
    "            input_ids = torch.tensor(batch['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
    "            sr_out = simple_model(input_ids, attention_mask)\n",
    "            dr_out = deep_model(input_ids, attention_mask)\n",
    "            \n",
    "            start_logits = dr_out.start_logits\n",
    "            end_logits = dr_out.end_logits\n",
    "            \n",
    "            # Greedy\n",
    "            for i in range(len(start_logits)):\n",
    "                start, end = torch.argmax(start_logits[i, :], dim=0), torch.argmax(end_logits[i, :], dim=0)\n",
    "                spans_greedy.append((start.item(), end.item()))\n",
    "            \n",
    "            # RV\n",
    "            for i, j, k in zip(sr_out, start_logits, end_logits):\n",
    "                rv, span = compute_rv(i, j, k, weight=.5)\n",
    "                rvs.append(rv)\n",
    "                spans_rv.append(span)\n",
    "    \n",
    "    predictions_metadata = {\n",
    "        'truth': truths,\n",
    "        'spans_greedy': spans_greedy,\n",
    "        'rvs': rvs,\n",
    "        'spans_rv': spans_rv,\n",
    "        'input_id_list': input_id_list\n",
    "    }\n",
    "    with open(f'predictions/EHReader/bioBERT_{dataset}_{split}.pickle', 'wb') as f:\n",
    "        pickle.dump(predictions_metadata, f)\n",
    "            \n",
    "    return predictions_metadata\n",
    "\n",
    "\n",
    "def evaluate_predictions(predictions_metadata, rv=False, threshold=-0.98, print_info=False):\n",
    "    if not rv:\n",
    "        spans_pred = predictions_metadata['spans_greedy']\n",
    "    else:\n",
    "        spans_pred = []\n",
    "        for rv, span_rv in zip(predictions_metadata['rvs'], predictions_metadata['spans_rv']):\n",
    "            if rv < threshold:\n",
    "                spans_pred.append(span_rv)\n",
    "            else:\n",
    "                spans_pred.append((0, 0))\n",
    "                \n",
    "    em = compute_exact_match(spans_pred, predictions_metadata['truth'])\n",
    "    f1 = compute_f1(spans_pred,  predictions_metadata['truth'], predictions_metadata['input_id_list'])\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'EM: {round(em*100, 1)}, F1: {round(f1*100, 1)}')\n",
    "        \n",
    "    return em, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ddd52",
   "metadata": {},
   "source": [
    "# Models and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee077c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = torch.load('models/SimpleReader/m_1_uf_e_2_vl_0.1676.model')\n",
    "with open('models/SimpleReader/m_1_uf_e_2_vl_0.1676_metadata.pickle', 'rb') as f:\n",
    "    simple_metadata = pickle.load(f)\n",
    "simple_model.to(device)\n",
    "simple_model.eval()\n",
    "\n",
    "deep_model = torch.load('models/bioBERT/m_1_uf_e_8_vl_0.7559.model')\n",
    "with open('models/bioBERT/m_1_uf_e_8_vl_0.7559_metadata.pickle', 'rb') as f:\n",
    "    deep_metadata = pickle.load(f)\n",
    "deep_model.to(device)\n",
    "deep_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda95014",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'medication'\n",
    "TEST_BATCH_SIZE = 32\n",
    "test_dataset = ermQA(f'{dataset}_qa_bio_test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8936f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/378 [00:00<?, ?it/s]C:\\Users\\lcwon\\Anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\lcwon\\Anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\lcwon\\Anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 378/378 [22:19<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "test_predictions_metadata = generate_predictions(simple_model, deep_model, test_loader, dataset, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5f0bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM: 59.3, F1: 60.8\n"
     ]
    }
   ],
   "source": [
    "em, f1 = evaluate_predictions(test_predictions_metadata, rv=False, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c015a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_list = []\n",
    "thresholds = []\n",
    "for threshold in np.arange(-1.5, 1.5, .01):\n",
    "    em, f1 = evaluate_predictions(test_predictions_metadata, rv=True, threshold=threshold, print_info=False)\n",
    "    em_list.append(em)\n",
    "    thresholds.append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c136f086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07999999999999874\n",
      "EM: 61.4, F1: 63.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6136739417989417, 0.633368762236497)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=thresholds, y=em_list)\n",
    "max_index = em_list.index(max(em_list))\n",
    "threshold = thresholds[max_index]\n",
    "\n",
    "print(threshold)\n",
    "evaluate_predictions(test_predictions_metadata, rv=True, threshold=threshold, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a12d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "train_dataset = ermQA(f'{dataset}_qa_bio_train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a084fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1134 [00:00<?, ?it/s]C:\\Users\\lcwon\\Anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\lcwon\\Anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\lcwon\\Anaconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  3%|▎         | 31/1134 [01:51<1:06:14,  3.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/4139569294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_predictions_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/3034661522.py\u001b[0m in \u001b[0;36mgenerate_predictions\u001b[1;34m(simple_model, deep_model, data_loader, dataset, split)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# RV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_logits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mrv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_rv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                 \u001b[0mrvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mspans_rv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/11651614.py\u001b[0m in \u001b[0;36mcompute_rv\u001b[1;34m(sr_logit, start_logit, end_logit, weight)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_rv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_logit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_logit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_logit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0ms_ext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_s_ext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_logit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0ms_diff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_span\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_tav_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_logit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_logit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ms_diff\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ms_ext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_span\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/11651614.py\u001b[0m in \u001b[0;36mcompute_tav_fast\u001b[1;34m(start_logit, end_logit)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mstart_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhigh_start_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mhigh_start_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhigh_start_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mend_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0ms_has\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_predictions_metadata = generate_predictions(simple_model, deep_model, train_loader, dataset, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7262683",
   "metadata": {},
   "outputs": [],
   "source": [
    "em, f1 = evaluate_predictions(train_predictions_metadata, rv=False, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b290ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_list = []\n",
    "thresholds = []\n",
    "for threshold in np.arange(-1.5, 1.5, .01):\n",
    "    em, f1 = evaluate_predictions(train_predictions_metadata, rv=True, threshold=threshold, print_info=False)\n",
    "    em_list.append(em)\n",
    "    thresholds.append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=thresholds, y=em_list)\n",
    "max_index = em_list.index(max(em_list))\n",
    "threshold = thresholds[max_index]\n",
    "\n",
    "print(threshold)\n",
    "evaluate_predictions(train_predictions_metadata, rv=True, threshold=-.54, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e79a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
