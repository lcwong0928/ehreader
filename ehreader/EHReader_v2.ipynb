{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5016,"status":"ok","timestamp":1638755254546,"user":{"displayName":"Yang Xiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03709122023087024418"},"user_tz":300},"id":"Pi_ngM91oekP","outputId":"be5f5fb2-ddc3-40bb-d599-ee603ab8d995"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.6)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.6.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2021.10.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (7.1.2)\n"]}],"source":["! pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":701,"status":"ok","timestamp":1638755255242,"user":{"displayName":"Yang Xiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03709122023087024418"},"user_tz":300},"id":"db7f6ecc","outputId":"0abd201d-3711-4725-e0ce-14217451a966"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"data":{"text/plain":["device(type='cpu')"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import json\n","import numpy as np\n","from collections import Counter\n","import pickle\n","from tqdm import tqdm\n","import seaborn as sns\n","import collections\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from transformers import BertTokenizer, TFBertForSequenceClassification, BertConfig ,DistilBertTokenizerFast, DistilBertForQuestionAnswering\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","from transformers import DistilBertModel, DistilBertConfig\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","\n","import pickle\n","import torch.optim as optim\n","\n","from google.colab import drive \n","drive.mount('/content/drive')\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b837d296"},"outputs":[],"source":["class ermQA(torch.utils.data.Dataset):\n","    def __init__(self, filename):\n","        with open(f\"/content/drive/Shareddrives/NLP/EHReader/processed_data/{filename}.pickle\", \"rb\") as f:\n","            self.encodings = pickle.load(f)\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01b87add"},"outputs":[],"source":["class DistilBERTEncoder(torch.nn.Module):\n","    def __init__(self, frozen=True):\n","        super(DistilBERTEncoder, self).__init__()\n","        self.encoder = DistilBertModel.from_pretrained('distilbert-base-uncased', output_hidden_states = True)\n","        self.encoder.to(device)\n","        if frozen:\n","            self.encoder.requires_grad = False\n","            self.encoder.eval()\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.encoder(input_ids, attention_mask = attention_mask)\n","        embedding = torch.cat([output[1][i] for i in [-1,-2,-3,-4]], dim=-1) # [batch, 512, 3072]\n","\n","        return embedding\n","    \n","    \n","class SimpleReader(torch.nn.Module):\n","  \n","    def __init__(self, in_features=3072, out_features=1):\n","        super(SimpleReader, self).__init__()\n","        self.linear = nn.Linear(in_features=in_features, out_features=out_features)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, embeddings):\n","        # Embedding for the first token ([CLS]) \n","        embedding_first_token = torch.squeeze(embeddings[:, 0, :], axis = 1) # [batch, 3072]    \n","        linear = self.linear(embedding_first_token) # [batch, 1] \n","        logit = self.sigmoid(linear)  # [batch, 1]   \n","        return logit\n","    \n","\n","class DeepReader(torch.nn.Module):\n","    def __init__(self, embed_size, num_heads):\n","        super(DeepReader, self).__init__()\n","        \n","        # Self attention on passage \n","        self.passage_key_linear = nn.Linear(embed_size, embed_size)\n","        self.passage_value_linear = nn.Linear(embed_size, embed_size)\n","        self.passage_query_linear = nn.Linear(embed_size, embed_size)\n","        self.passage_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n","\n","        # Self attention on question \n","        self.question_key_linear = nn.Linear(embed_size, embed_size)\n","        self.question_value_linear = nn.Linear(embed_size, embed_size)\n","        self.question_query_linear = nn.Linear(embed_size, embed_size)\n","        self.question_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n","\n","        # Cross attention \n","        self.cross_query_linear = nn.Linear(embed_size, embed_size)\n","        self.cross_key_linear = nn.Linear(embed_size, embed_size)\n","        self.cross_value_linear = nn.Linear(embed_size, embed_size)\n","        self.cross_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n","\n","        # Feed forward neural network (FFN)\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(embed_size, embed_size),\n","            nn.ReLU(),\n","            nn.Linear(embed_size, 2)\n","        )\n","        \n","    \n","    def forward(self, embeddings, token_split_index):\n","        passage, question = torch.tensor_split(embeddings, token_split_index, dim=1)\n","\n","        passage_key = self.passage_key_linear(passage)\n","        passage_value = self.passage_value_linear(passage)\n","        passage_query = self.passage_query_linear(passage)\n","        passage_after_attention, _ = self.passage_attention(query=passage_query, key=passage_key, value=passage_value)\n","\n","        question_key = self.question_key_linear(question)\n","        question_value = self.question_value_linear(question)\n","        question_query = self.question_query_linear(question)\n","        question_after_attention, _ = self.question_attention(query=question_query, key=question_key, value=question_value)\n","\n","        cross_query = self.cross_query_linear(passage_after_attention)\n","        cross_key = self.cross_key_linear(question_after_attention)\n","        cross_value = self.cross_value_linear(question_after_attention)\n","        cross_attention_embedding, _ = self.cross_attention(query=cross_query, key=cross_key, value=cross_value)\n","\n","        ffn_output = self.linear_relu_stack(cross_attention_embedding)\n","        output = nn.functional.softmax(ffn_output, dim=1)\n","\n","        return output, passage\n","\n","    \n","class EHReader(torch.nn.Module):\n","    def __init__(self):\n","        super(EHReader, self).__init__()\n","        self.encoder = DistilBERTEncoder(frozen=False)\n","        self.sr = SimpleReader(in_features=3072, out_features=1)\n","        self.dr = DeepReader(embed_size=3072, num_heads=1)\n","    \n","    def forward(self, input_ids, attention_mask):\n","        embedding = self.encoder(input_ids, attention_mask = attention_mask)\n","        \n","        sr_logits = self.sr(embedding)\n","        \n","        token_split_index = self.generate_token_split_index(input_ids)\n","        dr_logits, passage = self.dr(embedding, token_split_index)\n","        \n","        return sr_logits, dr_logits, passage\n","    \n","    def generate_token_split_index(self, input_ids):\n","        token_split_index = []\n","        sep_tokens = (input_ids == 102).nonzero(as_tuple=True)\n","        used_samples = set()\n","        for i, index in zip(sep_tokens[0], sep_tokens[1]):\n","            if i.item() not in used_samples:\n","                token_split_index.append(index.item())\n","                used_samples.add(i.item())\n","        return token_split_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e77cfc5"},"outputs":[],"source":["TRAIN_BATCH_SIZE = 1\n","train_dataset = ermQA('medication_qa_train')\n","train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n","\n","\n","VAL_BATCH_SIZE = 1\n","val_dataset = ermQA('medication_qa_val')\n","val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3344,"status":"ok","timestamp":1638755282195,"user":{"displayName":"Yang Xiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03709122023087024418"},"user_tz":300},"id":"4f641ef6","outputId":"41b7bc80-8432-416a-cc56-2e6dd32d4af5"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model = EHReader()\n","\n","# model = torch.load('models/EHReader/m_1_f_e_2_vl_2.9071.model')\n","# with open('models/EHReader/m_1_f_e_2_vl_2.9071.pickle', 'rb') as f:\n","#     metadata = pickle.load(f)\n","    \n","model.to(device)\n","metadata = dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1638755312443,"user":{"displayName":"Yang Xiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03709122023087024418"},"user_tz":300},"id":"ID64R-UIbU27","outputId":"5a25e8b0-7cae-4ca3-a100-78ce8dcda376"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["model.dr.cross_key_linear.weight.requires_grad"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1638755328292,"user":{"displayName":"Yang Xiang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03709122023087024418"},"user_tz":300},"id":"TrmTw3jubbdB","outputId":"162e6e9e-02cf-412c-eebd-adb513401d98"},"outputs":[{"data":{"text/plain":["Parameter containing:\n","tensor([[-0.0047,  0.0040, -0.0071,  ...,  0.0029,  0.0022,  0.0115],\n","        [ 0.0095, -0.0054,  0.0014,  ..., -0.0152,  0.0094, -0.0104],\n","        [-0.0121,  0.0176, -0.0076,  ...,  0.0175,  0.0076,  0.0109],\n","        ...,\n","        [ 0.0144,  0.0008,  0.0063,  ..., -0.0121, -0.0124,  0.0174],\n","        [-0.0034,  0.0009, -0.0050,  ..., -0.0077, -0.0112,  0.0144],\n","        [-0.0039, -0.0105, -0.0080,  ...,  0.0148,  0.0178,  0.0161]],\n","       requires_grad=True)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["model.dr.cross_key_linear.weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"error","timestamp":1638755532885,"user":{"displayName":"Yang Xiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnwjW17aEsvOQ28Odc-Ktx9WWw9Inp8K8BSjrR=s64","userId":"05580169903535072998"},"user_tz":300},"id":"16491246","outputId":"a8334537-1b44-4a81-972b-1326f096a471"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-2f12f4f40867\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msr_loss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["torch.cuda.empty_cache()\n","\n","NUM_EPOCHS = 20\n","\n","sr_loss_func = nn.BCELoss()\n","dr_loss_func = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=1, momentum=0.9)\n","\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","if metadata == {}:\n","    START_EPOCH = 0\n","    train_loss = []\n","    val_loss = []\n","else:\n","    START_EPOCH = metadata['epoch'] + 1\n","    train_loss = metadata['train_loss']\n","    val_loss = metadata['valid_loss']\n","\n","\n","# for epoch in range(START_EPOCH, START_EPOCH+NUM_EPOCHS):\n","for epoch in range(START_EPOCH, START_EPOCH+1):\n","    \n","    # Train\n","    batch_loss = []\n","    model.train()\n","    for batch in tqdm(train_loader):\n","        torch.cuda.empty_cache()\n","        \n","        # Forward \n","        input_ids = torch.tensor(batch['input_ids']).to(device)\n","        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n","        sr_out, dr_out, passage_embedding = model(input_ids, attention_mask)\n","\n","        # Calculate loss\n","        answerability = (batch['start_positions'] \u003c batch['end_positions']).view(-1, 1).float().to(device)\n","        sr_loss = sr_loss_func(sr_out, answerability)\n","\n","        target = torch.zeros(tuple(passage_embedding.shape[0:2]) + (2, )).to(device)\n","        start_pos = batch['start_positions'][0].item()\n","        end_pos = batch['end_positions'][0].item()\n","        target[0, start_pos, 0] = 1\n","        target[0, end_pos, 1] = 1\n","\n","        dr_loss = dr_loss_func(dr_out, target)\n","        \n","        total_loss = .5 * sr_loss + .5 * dr_loss\n","\n","        # Calculate loss and backward\n","        batch_loss.append(total_loss.item())\n","        optim.zero_grad()\n","        total_loss.backward()\n","        optim.step()\n","\n","        break \n","\n","    train_loss.append(np.mean(batch_loss))\n"," \n","        \n","    # Validation\n","    model.eval()\n","    batch_loss = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader):\n","            torch.cuda.empty_cache()\n","\n","            # Forward \n","            input_ids = torch.tensor(batch['input_ids']).to(device)\n","            attention_mask = torch.tensor(batch['attention_mask']).to(device)\n","            sr_out, dr_out, passage_embedding = model(input_ids, attention_mask)\n","\n","            # Calculate loss\n","            answerability = (batch['start_positions'] \u003c batch['end_positions']).view(-1, 1).float().to(device)\n","            sr_loss = sr_loss_func(sr_out, answerability)\n","\n","            target = torch.zeros(tuple(passage_embedding.shape[0:2]) + (2, )).to(device)\n","            start_pos = batch['start_positions'][0].item()\n","            end_pos = batch['end_positions'][0].item()\n","            target[0, start_pos, 0] = 1\n","            target[0, end_pos, 1] = 1\n","\n","            dr_loss = dr_loss_func(dr_out, target)\n","\n","            total_loss = .5 * sr_loss + .5 * dr_loss\n","            batch_loss.append(total_loss.item())\n","\n","    val_loss.append(np.mean(batch_loss))\n","    \n","    print(f'Epoch: {epoch}, train_loss: {train_loss[-1]}, val_loss: {val_loss[-1]}')\n","    \n","    model_name = f'models/EHReader/m_1_uf_e_{len(val_loss)}_vl_{round(val_loss[-1], 4)}'\n","    metadata = {\n","        'epoch': epoch,\n","        'train_loss': train_loss,\n","        'valid_loss': val_loss\n","    }\n","  \n","    # Early Stopping\n","    if len(val_loss) \u003e 3:\n","        if val_loss[-1] \u003e val_loss[-2] \u003e val_loss[-3]:\n","            torch.save(model, f'/content/drive/Shareddrives/NLP/EHReader/model/{model_name}.model')\n","            \n","            with open(f'/content/drive/Shareddrives/NLP/EHReader/model/{model_name}_metadata.pickle', 'wb') as f:\n","                pickle.dump(metadata, f)\n","            break\n","            \n","    # Check point\n","    torch.save(model, f'/content/drive/Shareddrives/NLP/EHReader/model/{model_name}.model') \n","\n","    with open(f'/content/drive/Shareddrives/NLP/EHReader/model/{model_name}_metadata.pickle', 'wb') as f:\n","        pickle.dump(metadata, f)"]},{"cell_type":"markdown","metadata":{"id":"5cfaa7fd"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6599018"},"outputs":[],"source":["def compute_exact_match(prediction, truth):\n","    exact_match = 0\n","    for pred, tru in zip(prediction, truth):\n","        if pred == tru:\n","            exact_match += 1\n","    return exact_match / len(prediction)\n","\n","\n","def getOverlap(a, b):\n","    return max(0, min(a[1], b[1]) - max(a[0], b[0]))\n","\n","\n","def compute_tav_fast(start_logits, end_logits):\n","    start_probs, end_probs = (torch.softmax(start_logits, dim=0), torch.softmax(end_logits, dim=0))\n","    n = len(start_logits)\n","    s_null = start_probs[0] + end_probs[0]\n","    s_has = 0\n","    best_span = (0, 0)\n","    high_start_idx = 1\n","  \n","    for i in range(1, n):\n","        if start_probs[i] \u003e start_probs[high_start_idx]:\n","            high_start_idx = i\n","        if start_probs[high_start_idx] + end_probs[i] \u003e s_has:\n","            s_has = start_probs[high_start_idx] + end_probs[i]\n","            best_span = (high_start_idx, i)\n","            \n","    s_diff = s_null - s_has\n","    return s_diff.item(), best_span\n","\n","\n","def compute_rv(sr_logit, dr_logit):\n","    \n","    s_ext = (1-2*sr_logit.item())\n","    \n","    start_logits, end_logits = dr_logit[:, 0], dr_logit[:, 1]\n","    s_diff, best_span = compute_tav_fast(start_logits, end_logits)\n","    \n","    v = .5 * s_diff + .5 * s_ext\n","    return v, best_span\n","\n","def compute_f1(prediction, truth, input_id_list):\n","    \n","    f1_scores = []\n","    \n","    for i, (pred, gold) in enumerate(zip(prediction, truth)):\n","        \n","        if pred == gold:\n","            f1_scores.append(1)\n","            \n","        else:\n","            pred_tokens = input_id_list[i-1][pred[0]: pred[1]+1]\n","            gold_tokens = input_id_list[i-1][gold[0]: gold[1]+1]\n","\n","            total_overlap = len(set(pred_tokens).intersection(set(gold_tokens)))\n","            total_tru = len(gold_tokens)\n","            total_pred = len(pred_tokens)\n","\n","            if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n","                f1_scores.append(int(pred_tokens == gold_tokens))\n","            elif total_overlap == 0:\n","                f1_scores.append(0)\n","            else:\n","                prec = total_overlap / total_pred\n","                rec = total_overlap / total_tru\n","                f1_scores.append(2 * (prec * rec) / (prec + rec))\n","    \n","    return np.mean(f1_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"524b5333"},"outputs":[],"source":["def generate_predictions(model, data_loader, split):\n","    truths = []\n","    \n","    # Greedy\n","    spans_greedy = []\n","    \n","    # RV\n","    s_diffs = []\n","    spans_rv = []\n","    \n","    input_id_list = []\n","    \n","    model.eval()\n","    for batch in tqdm(data_loader):\n","        \n","        # we don't need to calculate gradients as we're not training\n","        with torch.no_grad():\n","            # Truth Span\n","            for i, j, k in zip(batch['start_positions'], batch['end_positions'], batch['input_ids']):\n","                truths.append((i.item(), j.item()))\n","                input_id_list.append(k.tolist())\n","        \n","            # Predictions\n","            input_ids = torch.tensor(batch['input_ids']).to(device)\n","            attention_mask = torch.tensor(batch['attention_mask']).to(device)\n","            sr_out, dr_out, _ = model(input_ids, attention_mask)\n","            \n","            # Greedy\n","            for i in dr_out:\n","                start, end = torch.argmax(i[:, 0], dim=0), torch.argmax(i[:, 1], dim=0)\n","                spans_greedy.append((start.item(), end.item()))\n","            \n","            # RV\n","            for i, j in zip(sr_out, dr_out):\n","                s_diff, span = compute_rv(i, j)\n","                s_diffs.append(s_diff)\n","                spans_rv.append(span)\n","    \n","    predictions_metadata = {\n","        'truth': truths,\n","        'spans_greedy': spans_greedy,\n","        's_diffs': s_diffs,\n","        'spans_rv': spans_rv,\n","        'input_id_list': input_id_list\n","    }\n","    with open(f'predictions/EHReader/unfrozen_medication_{split}.pickle', 'wb') as f:\n","        pickle.dump(predictions_metadata, f)\n","            \n","    return predictions_metadata\n","\n","\n","def evaluate_predictions(predictions_metadata, rv=False, threshold=-0.98, print_info=False):\n","    if not rv:\n","        spans_pred = predictions_metadata['spans_greedy']\n","    else:\n","        spans_pred = []\n","        for s_diff, span_rv in zip(predictions_metadata['s_diffs'], predictions_metadata['spans_rv']):\n","            if s_diff \u003c threshold:\n","                spans_pred.append(span_rv)\n","            else:\n","                spans_pred.append((0, 0))\n","                \n","    em = compute_exact_match(spans_pred, predictions_metadata['truth'])\n","    f1 = compute_f1(spans_pred,  predictions_metadata['truth'], predictions_metadata['input_id_list'])\n","    \n","    if print_info:\n","        print(f'EM: {round(em*100, 1)}, F1: {round(f1*100, 1)}')\n","        \n","    return em, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bd90872"},"outputs":[],"source":["TEST_BATCH_SIZE = 1\n","test_dataset = ermQA('medication_qa_test')\n","test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n","\n","train_dataset = ermQA('medication_qa_train')\n","train_loader = DataLoader(train_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n","\n","model = torch.load('models/EHReader/m_1_f_e_1_vl_2.8547.model')\n","with open('models/EHReader/m_1_f_e_1_vl_2.8547_metadata.pickle', 'rb') as f:\n","    metadata = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d3046b20"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/12096 [00:00\u003c?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"," 53%|█████▎    | 6362/12096 [5:00:09\u003c4:28:08,  2.81s/it]"]}],"source":["test_predictions_metadata = generate_predictions(model, test_loader, 'test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3a9c897","outputId":"5e7ec33c-8040-41fa-9ede-5aa4b3542726"},"outputs":[{"name":"stdout","output_type":"stream","text":["EM: 50.0, F1: 50.0\n"]}],"source":["em, f1 = evaluate_predictions(test_predictions_metadata, rv=False, print_info=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80bf4d65","outputId":"e8b657ce-ea97-4097-a017-cb90e71c658c"},"outputs":[{"name":"stdout","output_type":"stream","text":["EM: 0.0, F1: 0.3\n"]}],"source":["em, f1 = evaluate_predictions(test_predictions_metadata, rv=True, threshold=-0.1, print_info=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa1fb59f"},"outputs":[],"source":["em_list = []\n","thresholds = []\n","for threshold in np.arange(-1, 1, .01):\n","    em, f1 = evaluate_predictions(test_predictions_metadata, rv=True, threshold=threshold, print_info=False)\n","    em_list.append(em)\n","    thresholds.append(threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b034168c","outputId":"b87e8b7d-f089-4ed0-efe8-05b7b82567b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5000000000000013\n","EM: 50.0, F1: 50.0\n"]},{"data":{"text/plain":["(0.5, 0.5)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["sns.lineplot(x=thresholds, y=em_list)\n","max_index = em_list.index(max(em_list))\n","threshold = thresholds[max_index]\n","print(threshold)\n","evaluate_predictions(test_predictions_metadata, rv=True, threshold=threshold, print_info=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd4de5ae"},"outputs":[],"source":["train_predictions_metadata = generate_predictions(model, train_loader, 'train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf8ab0de"},"outputs":[],"source":["em, f1 = evaluate_predictions(train_predictions_metadata, rv=False, print_info=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f859534b"},"outputs":[],"source":["em_list = []\n","thresholds = []\n","for threshold in np.arange(-1, 1, .01):\n","    em, f1 = evaluate_predictions(train_predictions_metadata, rv=True, threshold=threshold, print_info=False)\n","    em_list.append(em)\n","    thresholds.append(threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2fe376d"},"outputs":[],"source":["sns.lineplot(x=thresholds, y=em_list)\n","max_index = em_list.index(max(em_list))\n","threshold = thresholds[max_index]\n","print(threshold)\n","evaluate_predictions(train_predictions_metadata, rv=True, threshold=threshold, print_info=True)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"EHReader_v2.ipynb","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":5}