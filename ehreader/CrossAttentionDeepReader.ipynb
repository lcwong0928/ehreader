{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CrossAttentionDeepReader.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMeNLXcXv0b2YvvNY577zOc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"088b7a2ef9094d8195976afbe507df2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8678b156834c49698f285405d7efaf7a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c0baf2f2122424c81e49de4f43e80e6","IPY_MODEL_8cb11378e171408eb62aa236904efdc7","IPY_MODEL_9eaef1e8b27d47ea831c0a43f926ca29"]}},"8678b156834c49698f285405d7efaf7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c0baf2f2122424c81e49de4f43e80e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b4163a580b6a479ca36177493bd3a080","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c6627658a894ed09764d387c2d2c7f3"}},"8cb11378e171408eb62aa236904efdc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ac2c7db8ad7408c8afd7f433a90c4fb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":483,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":483,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dacf94f6403f46b18d32c9dc8a06eb09"}},"9eaef1e8b27d47ea831c0a43f926ca29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e24867b95066442084a8adccd2c12302","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 483/483 [00:00&lt;00:00, 19.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a34d3e0aa3b4581992b82d3491586bf"}},"b4163a580b6a479ca36177493bd3a080":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5c6627658a894ed09764d387c2d2c7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ac2c7db8ad7408c8afd7f433a90c4fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dacf94f6403f46b18d32c9dc8a06eb09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e24867b95066442084a8adccd2c12302":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9a34d3e0aa3b4581992b82d3491586bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9a2fd37996142f7a239a59e5d934716":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a6c1d770b1c64ab3a3cbd323f380ad0e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6901492449634d5983e468d6c17d51fe","IPY_MODEL_9e20f9185d6f417088a1a1fca5153ffb","IPY_MODEL_b8123a8816f745d5a33e8279ad14f846"]}},"a6c1d770b1c64ab3a3cbd323f380ad0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6901492449634d5983e468d6c17d51fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c08dd2340e22465fb55910b40df01415","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e31de1b82ee94bf2bb8a42da3eb15d40"}},"9e20f9185d6f417088a1a1fca5153ffb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_83153f9ebbaf4a52b03b06a3330e8587","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":267967963,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267967963,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a45257dd7924eeca25f157a1c5d8b8c"}},"b8123a8816f745d5a33e8279ad14f846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ce35bca4a71e4c538e266bd53cc564cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256M/256M [00:04&lt;00:00, 53.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a1fb0e039ce4e3a861765d4200d94df"}},"c08dd2340e22465fb55910b40df01415":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e31de1b82ee94bf2bb8a42da3eb15d40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83153f9ebbaf4a52b03b06a3330e8587":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1a45257dd7924eeca25f157a1c5d8b8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce35bca4a71e4c538e266bd53cc564cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a1fb0e039ce4e3a861765d4200d94df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGgc7gbn71m8","executionInfo":{"status":"ok","timestamp":1638834484636,"user_tz":300,"elapsed":209,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}},"outputId":"55c09f1c-acb0-4ae2-b22b-79180d9725e9"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 9.9 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 61.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 667 kB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 99.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1OBJi0C76Gs","executionInfo":{"status":"ok","timestamp":1638834662659,"user_tz":300,"elapsed":17438,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}},"outputId":"f40e7aef-3d31-466a-eb4a-e8873741783d"},"source":["import pandas as pd\n","import json\n","import numpy as np\n","from collections import Counter\n","import pickle\n","from tqdm import tqdm\n","import seaborn as sns\n","import collections\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from transformers import BertTokenizer, TFBertForSequenceClassification, BertConfig ,DistilBertTokenizerFast, DistilBertForQuestionAnswering\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","from transformers import DistilBertModel, DistilBertConfig\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","\n","import pickle\n","import torch.optim as optim\n","\n","from google.colab import drive \n","drive.mount('/content/drive')\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","device"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"KtClM0Qr77T7","executionInfo":{"status":"ok","timestamp":1638834663087,"user_tz":300,"elapsed":3,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}}},"source":["class ermQA(torch.utils.data.Dataset):\n","    def __init__(self, filename):\n","        with open(f\"/content/drive/Shareddrives/NLP/EHReader/processed_data/{filename}.pickle\", \"rb\") as f:\n","            self.encodings = pickle.load(f)\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"STpjeb6A7857","executionInfo":{"status":"ok","timestamp":1638834665138,"user_tz":300,"elapsed":259,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}}},"source":["class DistilBERTEncoder(torch.nn.Module):\n","    def __init__(self, frozen=True):\n","        super(DistilBERTEncoder, self).__init__()\n","        self.encoder = DistilBertModel.from_pretrained('distilbert-base-uncased', output_hidden_states = True)\n","        self.encoder.to(device)\n","        if frozen:\n","            self.encoder.requires_grad = False\n","            self.encoder.eval()\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.encoder(input_ids, attention_mask = attention_mask)\n","        embedding = output.last_hidden_state # [batch, 512, 3072]\n","\n","        return embedding\n","    \n","class DeepReader(torch.nn.Module):\n","    def __init__(self, embed_size=768, num_heads=1):\n","        super(DeepReader, self).__init__()\n","        self.encoder = DistilBERTEncoder(frozen=False)\n","        \n","        # Self attention on passage \n","        self.passage_key_linear = nn.Linear(embed_size, embed_size)\n","        self.passage_value_linear = nn.Linear(embed_size, embed_size)\n","        self.passage_query_linear = nn.Linear(embed_size, embed_size)\n","        self.passage_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n","\n","        # Self attention on question \n","        self.question_key_linear = nn.Linear(embed_size, embed_size)\n","        self.question_value_linear = nn.Linear(embed_size, embed_size)\n","        self.question_query_linear = nn.Linear(embed_size, embed_size)\n","        self.question_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n","\n","        # Cross attention \n","        self.cross_query_linear = nn.Linear(embed_size, embed_size)\n","        self.cross_key_linear = nn.Linear(embed_size, embed_size)\n","        self.cross_value_linear = nn.Linear(embed_size, embed_size)\n","        self.cross_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads, batch_first=True)\n","\n","        # Feed forward neural network (FFN)\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(embed_size, embed_size),\n","            nn.ReLU(),\n","            nn.Linear(embed_size, 2)\n","        )\n","    \n","    def forward(self, input_ids, attention_mask):\n","        embeddings = self.encoder(input_ids, attention_mask = attention_mask)\n","        \n","        token_split_index = self.generate_token_split_index(input_ids)\n","\n","        passage, question = torch.tensor_split(embeddings, token_split_index, dim=1)\n","\n","        passage_key = self.passage_key_linear(passage)\n","        passage_value = self.passage_value_linear(passage)\n","        passage_query = self.passage_query_linear(passage)\n","        passage_after_attention, _ = self.passage_attention(query=passage_query, key=passage_key, value=passage_value)\n","\n","        question_key = self.question_key_linear(question)\n","        question_value = self.question_value_linear(question)\n","        question_query = self.question_query_linear(question)\n","        question_after_attention, _ = self.question_attention(query=question_query, key=question_key, value=question_value)\n","\n","        cross_query = self.cross_query_linear(passage_after_attention)\n","        cross_key = self.cross_key_linear(question_after_attention)\n","        cross_value = self.cross_value_linear(question_after_attention)\n","        cross_attention_embedding, _ = self.cross_attention(query=cross_query, key=cross_key, value=cross_value)\n","\n","        ffn_output = self.linear_relu_stack(cross_attention_embedding)\n","        output = nn.functional.softmax(ffn_output, dim=1)\n","\n","        return output\n","    \n","    def generate_token_split_index(self, input_ids):\n","        token_split_index = []\n","        sep_tokens = (input_ids == 102).nonzero(as_tuple=True)\n","        used_samples = set()\n","        for i, index in zip(sep_tokens[0], sep_tokens[1]):\n","            if i.item() not in used_samples:\n","                token_split_index.append(index.item())\n","                used_samples.add(i.item())\n","        return token_split_index"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Acq5F6cG8CGg","executionInfo":{"status":"ok","timestamp":1638834685032,"user_tz":300,"elapsed":17670,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}}},"source":["TRAIN_BATCH_SIZE = 1\n","train_dataset = ermQA('medication_qa_train')\n","train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n","\n","\n","VAL_BATCH_SIZE = 1\n","val_dataset = ermQA('medication_qa_val')\n","val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133,"referenced_widgets":["088b7a2ef9094d8195976afbe507df2d","8678b156834c49698f285405d7efaf7a","1c0baf2f2122424c81e49de4f43e80e6","8cb11378e171408eb62aa236904efdc7","9eaef1e8b27d47ea831c0a43f926ca29","b4163a580b6a479ca36177493bd3a080","5c6627658a894ed09764d387c2d2c7f3","8ac2c7db8ad7408c8afd7f433a90c4fb","dacf94f6403f46b18d32c9dc8a06eb09","e24867b95066442084a8adccd2c12302","9a34d3e0aa3b4581992b82d3491586bf","a9a2fd37996142f7a239a59e5d934716","a6c1d770b1c64ab3a3cbd323f380ad0e","6901492449634d5983e468d6c17d51fe","9e20f9185d6f417088a1a1fca5153ffb","b8123a8816f745d5a33e8279ad14f846","c08dd2340e22465fb55910b40df01415","e31de1b82ee94bf2bb8a42da3eb15d40","83153f9ebbaf4a52b03b06a3330e8587","1a45257dd7924eeca25f157a1c5d8b8c","ce35bca4a71e4c538e266bd53cc564cf","5a1fb0e039ce4e3a861765d4200d94df"]},"id":"Xs7knT9K8ESx","executionInfo":{"status":"ok","timestamp":1638834702050,"user_tz":300,"elapsed":17030,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}},"outputId":"02f04fec-1023-449c-83ae-5fb80400c3e2"},"source":["model = DeepReader()\n","model.to(device)\n","metadata = dict()\n","\n","if metadata == dict():\n","    START_EPOCH = 0\n","    train_loss = []\n","    val_loss = []\n","else:\n","    START_EPOCH = metadata['epoch'] + 1\n","    train_loss = metadata['train_loss']\n","    val_loss = metadata['valid_loss']"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"088b7a2ef9094d8195976afbe507df2d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9a2fd37996142f7a239a59e5d934716","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":779},"id":"7b-YtxIF8FOc","executionInfo":{"status":"error","timestamp":1638837027509,"user_tz":300,"elapsed":2324916,"user":{"displayName":"Lawrence Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjR6uDFGuAfj3Lq8qxlFTz6m4EWvLDfD7DVyrxn4Q=s64","userId":"01088651821611722086"}},"outputId":"76d52203-61b5-42a2-c0c8-ce5f6954b1ed"},"source":["NUM_EPOCHS = 2\n","dr_loss_func = nn.CrossEntropyLoss()\n","optim = AdamW(model.parameters(), lr=3e-5)\n","\n","for epoch in range(START_EPOCH, START_EPOCH+NUM_EPOCHS):\n","    # Train\n","    model.train()\n","    batch_loss = []\n","    current_loss = []\n","    for batch in tqdm(train_loader):\n","        torch.cuda.empty_cache()\n","        \n","        # Forward \n","        input_ids = torch.tensor(batch['input_ids']).to(device)\n","        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n","        dr_out = model(input_ids, attention_mask)\n","\n","        # Calculate dr loss\n","        start_logits, end_logits = dr_out.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1).contiguous()\n","        end_logits = end_logits.squeeze(-1).contiguous()\n","\n","        start_loss = dr_loss_func(start_logits,  batch['start_positions'].to(device))\n","        end_loss = dr_loss_func(end_logits, batch['end_positions'].to(device))\n","        dr_loss = (start_loss + end_loss) / 2\n","\n","        # Calculate loss and backward\n","        current_loss.append(dr_loss)\n","        if len(current_loss) == 32:\n","          total_loss = sum(current_loss) / 32 \n","          batch_loss.append(total_loss.item())\n","          optim.zero_grad()\n","          total_loss.backward()\n","          optim.step()\n","          current_loss = []\n","          if len(batch_loss) % 100 == 0:\n","            print(np.mean(batch_loss))\n","\n","    train_loss.append(np.mean(batch_loss))\n","  \n","    # Validation\n","    model.eval()\n","    batch_loss = []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader):\n","            torch.cuda.empty_cache()\n","\n","            # Forward \n","            input_ids = torch.tensor(batch['input_ids']).to(device)\n","            attention_mask = torch.tensor(batch['attention_mask']).to(device)\n","            dr_out = model(input_ids, attention_mask)\n","\n","            # Calculate dr loss\n","            start_logits, end_logits = dr_out.split(1, dim=-1)\n","            start_logits = start_logits.squeeze(-1).contiguous()\n","            end_logits = end_logits.squeeze(-1).contiguous()\n","\n","            start_loss = dr_loss_func(start_logits,  batch['start_positions'].to(device))\n","            end_loss = dr_loss_func(end_logits, batch['end_positions'].to(device))\n","            dr_loss = (start_loss + end_loss) / 2\n","\n","            # Calculate loss and backward\n","            current_loss.append(dr_loss)\n","            if len(current_loss) == 32:\n","              total_loss = sum(current_loss) / 32 \n","              batch_loss.append(total_loss.item())\n","              current_loss = []\n","\n","    val_loss.append(np.mean(batch_loss))\n","    \n","    print(f'Epoch: {epoch}, train_loss: {train_loss[-1]}, val_loss: {val_loss[-1]}')\n","    \n","    model_name = f'/content/drive/Shareddrives/NLP/EHReader/DeepReader/m_1_uf_e_{len(val_loss)}_vl_{round(val_loss[-1], 4)}'\n","    metadata = {\n","        'epoch': epoch,\n","        'train_loss': train_loss,\n","        'valid_loss': val_loss\n","    }\n","  \n","    # Early Stopping\n","    if len(val_loss) > 3:\n","        if val_loss[-1] > val_loss[-2] > val_loss[-3]:\n","            torch.save(model, f'{model_name}.model')\n","            \n","            with open(f'{model_name}_metadata.pickle', 'wb') as f:\n","                pickle.dump(metadata, f)\n","            \n","    # Check point\n","    torch.save(model, f'{model_name}.model') \n","\n","    with open(f'{model_name}_metadata.pickle', 'wb') as f:\n","        pickle.dump(metadata, f)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/36288 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n","  9%|▉         | 3197/36288 [03:08<19:28, 28.31it/s]"]},{"output_type":"stream","name":"stdout","text":["5.714346036911011\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 6396/36288 [06:17<18:00, 27.67it/s]"]},{"output_type":"stream","name":"stdout","text":["5.713166468143463\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 9596/36288 [09:27<16:11, 27.48it/s]"]},{"output_type":"stream","name":"stdout","text":["5.710565487543742\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 12796/36288 [12:36<14:06, 27.75it/s]"]},{"output_type":"stream","name":"stdout","text":["5.707761924266816\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 15996/36288 [15:46<12:00, 28.18it/s]"]},{"output_type":"stream","name":"stdout","text":["5.706523044586182\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 19197/36288 [18:55<10:06, 28.19it/s]"]},{"output_type":"stream","name":"stdout","text":["5.705400544007619\n"]},{"output_type":"stream","name":"stderr","text":[" 62%|██████▏   | 22396/36288 [22:05<08:15, 28.03it/s]"]},{"output_type":"stream","name":"stdout","text":["5.706202387809753\n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████   | 25600/36288 [25:15<12:25, 14.33it/s]"]},{"output_type":"stream","name":"stdout","text":["5.7070645874738695\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 28799/36288 [28:24<04:25, 28.22it/s]"]},{"output_type":"stream","name":"stdout","text":["5.705572285652161\n"]},{"output_type":"stream","name":"stderr","text":[" 88%|████████▊ | 31999/36288 [31:33<02:27, 29.10it/s]"]},{"output_type":"stream","name":"stdout","text":["5.706065826892853\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 35199/36288 [34:43<00:38, 28.29it/s]"]},{"output_type":"stream","name":"stdout","text":["5.7061049565401945\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 36288/36288 [35:48<00:00, 16.89it/s]\n","  0%|          | 0/12096 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","100%|██████████| 12096/12096 [02:42<00:00, 74.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, train_loss: 5.705892985459989, val_loss: 5.709470722410414\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 223/36288 [00:12<34:42, 17.31it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e44fbb3e3eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m           \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"23JhO5Kv8i2b"},"source":[""],"execution_count":null,"outputs":[]}]}